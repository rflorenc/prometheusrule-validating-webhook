apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  generation: 1
  labels:

    mock.example.com/resource: "true"
    custom-key: "abcd"
  name: mock-example-prometheus-rules-bad
  namespace: test-abc
  resourceVersion: "207061206"
  selfLink: /apis/monitoring.coreos.com/v1/namespaces/example/prometheusrules/mock-prometheus-rules
  uid: 8b748d90-1646-43a9-8c97-386d943cb805
spec:
  groups:
  - name: test-example-apps
    rules:
    - alert: KubePodCrashLooping
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
          }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
      expr: |
        rate(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[15m]) * 60 * 5 > 0
      for: 15m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        #example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubePodNotReady
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready
          state for longer than 15 minutes.
      expr: |
        sum by (namespace, pod) (
          max by(namespace, pod) (
            kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown"}
          ) * on(namespace, pod) group_left(owner_kind) topk by(namespace, pod) (
            1, max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"})
          )
        ) > 0
      for: 15m
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeDeploymentGenerationMismatch
      annotations:
        message: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment
          }} does not match, this indicates that the Deployment has failed but has
          not been rolled back.
      expr: |
        kube_deployment_status_observed_generation{job="kube-state-metrics"}
          !=
        kube_deployment_metadata_generation{job="kube-state-metrics"}
      for: 15m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeDeploymentReplicasMismatch
      annotations:
        message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not
          matched the expected number of replicas for longer than 15 minutes.
      expr: |
        (
          kube_deployment_spec_replicas{job="kube-state-metrics"}
            !=
          kube_deployment_status_replicas_available{job="kube-state-metrics"}
        ) and (
          changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[5m])
            ==
          0
        )
      for: 15m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeStatefulSetReplicasMismatch
      annotations:
        message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has
          not matched the expected number of replicas for longer than 15 minutes.
      expr: |
        (
          kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
            !=
          kube_statefulset_status_replicas{job="kube-state-metrics"}
        ) and (
          changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])
            ==
          0
        )
      for: 15m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeStatefulSetGenerationMismatch
      annotations:
        message: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset
          }} does not match, this indicates that the StatefulSet has failed but has
          not been rolled back.
      expr: |
        kube_statefulset_status_observed_generation{job="kube-state-metrics"}
          !=
        kube_statefulset_metadata_generation{job="kube-state-metrics"}
      for: 15m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeStatefulSetUpdateNotRolledOut
      annotations:
        message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update
          has not been rolled out.
      expr: |
        max without (revision) (
          kube_statefulset_status_current_revision{job="kube-state-metrics"}
            unless
          kube_statefulset_status_update_revision{job="kube-state-metrics"}
        )
          *
        (
          kube_statefulset_replicas{job="kube-state-metrics"}
            !=
          kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
        )
      for: 15m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeDaemonSetRolloutStuck
      annotations:
        message: Only {{ $value | humanizePercentage }} of the desired Pods of DaemonSet
          {{ $labels.namespace }}/{{ $labels.daemonset }} are scheduled and ready.
      expr: |
        kube_daemonset_status_number_ready{job="kube-state-metrics"}
          /
        kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} < 1.00
      for: 15m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeContainerWaiting
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container}}
          has been in waiting state for longer than 1 hour.
      expr: |
        sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{job="kube-state-metrics"}) > 0
      for: 1h
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeDaemonSetNotScheduled
      annotations:
        message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset
          }} are not scheduled.'
      expr: |
        kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
          -
        kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
      for: 10m
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeDaemonSetMisScheduled
      annotations:
        message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset
          }} are running where they are not supposed to run.'
      expr: |
        kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
      for: 15m
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeCronJobRunning
      annotations:
        message: CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking more
          than 1h to complete.
      expr: |
        time() - kube_cronjob_next_schedule_time{job="kube-state-metrics"} > 3600
      for: 1h
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeJobCompletion
      annotations:
        message: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more
          than one hour to complete.
      expr: |
        kube_job_spec_completions{job="kube-state-metrics"} - kube_job_status_succeeded{job="kube-state-metrics"} > 0
      for: 1h
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeJobFailed
      annotations:
        message: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete.
      expr: |
        kube_job_failed{job="kube-state-metrics"} > 0
      for: 15m
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeHpaReplicasMismatch
      annotations:
        message: HPA {{ $labels.namespace }}/{{ $labels.hpa }} has not matched the
          desired number of replicas for longer than 15 minutes.
      expr: |
        (kube_hpa_status_desired_replicas{job="kube-state-metrics"}
          !=
        kube_hpa_status_current_replicas{job="kube-state-metrics"})
          and
        changes(kube_hpa_status_current_replicas[15m]) == 0
      for: 15m
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubeHpaMaxedOut
      annotations:
        message: HPA {{ $labels.namespace }}/{{ $labels.hpa }} has been running at
          max replicas for longer than 15 minutes.
      expr: |
        kube_hpa_status_current_replicas{job="kube-state-metrics"}
          ==
        kube_hpa_spec_max_replicas{job="kube-state-metrics"}
      for: 15m
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL

  - name: test-example-kube-storage
    rules:
    - alert: KubePersistentVolumeFillingUp
      annotations:
        message: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim
          }} in Namespace {{ $labels.namespace }} is only {{ $value | humanizePercentage
          }} free.
      expr: |
        kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
          /
        kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
          < 0.03
      for: 1m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubePersistentVolumeFillingUp
      annotations:
        message: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim
          }} in Namespace {{ $labels.namespace }} is expected to fill up within four
          days. Currently {{ $value | humanizePercentage }} is available.
      expr: |
        (
          kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubelet", metrics_path="/metrics"}
        ) < 0.15 and predict_linear(kubelet_volume_stats_available_bytes{job="kubelet", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
      for: 1h
      labels:
        severity: warning
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
    - alert: KubePersistentVolumeErrors
      annotations:
        message: The persistent volume {{ $labels.persistentvolume }} has status {{
          $labels.phase }}.
      expr: |
        kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
      for: 5m
      labels:
        severity: critical
        example_alarm_type: AUTO_OM
        example_alerting_email: ricardo.lourenco@example.com
        example_incident: "True"
        example_response_code: ""
        example_response_code_type: MAIL
